{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis y calibración de técnicas de aprendizaje máquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Conjuntos de datos de prueba en sklearn que utlizaremos\n",
    "#----------------------------------------------------------\n",
    "\n",
    "# Los conjuntos artificiales típicos para probar datos\n",
    "from sklearn.datasets import make_moons           # En forma de medialunas \n",
    "from sklearn.datasets import make_circles         # En forma de círculos\n",
    "from sklearn.datasets import make_classification  # Como separación lineal\n",
    "\n",
    "# Conjunto de datos de dífgitos escritos a mano, versión reducida\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "\n",
    "# Los métodos de aprendizaje a utilizar ya provenientes de sklearn\n",
    "#------------------------------------------------------------------\n",
    "from sklearn.neighbors import KNeighborsClassifier      # KNN\n",
    "from sklearn.svm import SVC                             # SVM\n",
    "from sklearn.tree import DecisionTreeClassifier         # Arbol decisión\n",
    "from sklearn.ensemble import RandomForestClassifier     # Bósque aleatorios\n",
    "from sklearn.ensemble import AdaBoostClassifier         # ADA Boost\n",
    "from sklearn.naive_bayes import GaussianNB              # Naive bayes\n",
    "from sklearn.linear_model import  LogisticRegression    # Logística con regularización\n",
    "\n",
    "# Logística con polinomio de orden 2\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis    \n",
    "\n",
    "\n",
    "# Métodos de preprocesamiento que utilizaremos\n",
    "#----------------------------------------------\n",
    "\n",
    "# Para normalizar los datos (media y desviación estandar)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Para hacer análisis en componentes principales\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Métodos de validación cruzada de sklearn que utilizaremos\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "# Para separar los datos en entrenamiento y validación\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Genera conjuntos de datos para validación cruzada\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Para encontrar el mejor valor de un parámetro\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Métodos de curvas de aprendizaje y análisis \n",
    "# ---------------------------------------------\n",
    "\n",
    "# Para hacer curvas de aprendizaje\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Para hacer curvas de validación\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "\n",
    "# Establecer un flujo de trabajo de ML\n",
    "#-------------------------------------\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Comparasión de diferentes clasificadores\n",
    "\n",
    "Muestra para 3 conjuntos de datos artificiales bidimensionales, la forma en que se realiza la clasificación con distintos métodos. Principalmente lo hacemos para poder sacar conclusiones sobre en que situaciones un método puede ser mejor que otros, y que está haciendo internamente.\n",
    "\n",
    "Codigo obtenido de la documentación de scikit-learn, el cual se puede consultar [aquí](http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Generando 3 conjuntos de aprendizaje sintéticos\n",
    "ara probar como funcionan los diferentes tipos de clasificadores, primero vamos a revisar cual es el tipo de partición del espacio que se espera con cada uno de ellos en 3 casos diferentes. Para los tres casos se va a generar 3 conjuntos de datos sintéticos es dos dimensiones (con el fin de graficar las diferencias).\n",
    "\n",
    "Estos tres conjuntos son de la siguiente forma:\n",
    "\n",
    "1. El primer conjunto tiene forma de media luna los datos de una clase respecto a la otra.\n",
    "\n",
    "2. En el segundo conjunto de datos, los datos de las dos clases están en círculos concéntricos.\n",
    "\n",
    "3. El tercer caso son datos linealmente separables con ruido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos en forma de media luna\n",
    "X1, y1 = make_moons(noise=0.3, random_state=0)\n",
    "\n",
    "# Datos en forma de círculos\n",
    "X2, y2 = make_circles(noise=0.2, factor=0.5, random_state=1)\n",
    "\n",
    "# Datos en forma de regresion lineal\n",
    "X3, y3 = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                             random_state=1, n_clusters_per_class=1)\n",
    "# Le agregamos ruido para hacerlos interesantes\n",
    "rng = np.random.RandomState(2)\n",
    "X3 += 2 * rng.uniform(size=X3.shape)\n",
    "\n",
    "# Los conjuntos de datos irdenados como una lista de pares ordenados\n",
    "datasets = [(X1, y1), (X2, y2), (X3, y3)]\n",
    "\n",
    "# Y los grafiacamos para verlos\n",
    "figure = plt.figure(figsize=(30, 10))\n",
    "cm_escala = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "for (i, ds) in enumerate(datasets):\n",
    "\n",
    "    # Selecciona los valores del conjunto de datos y los escala\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Grafica\n",
    "    ax = plt.subplot(1, 3, i+1)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=150, cmap=cm_escala)\n",
    "    ax.set_xlim(X[:, 0].min() - .5, X[:, 0].max() + .5)\n",
    "    ax.set_ylim(X[:, 1].min() - .5, X[:, 1].max() + .5)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "figure.subplots_adjust(left=.02, right=.98)    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Definiendo una la bateria de clasificadores diferentes\n",
    "\n",
    "En esta sección se va a generar una batería de diferentes objetos clasificador, cada uno proveniente de una técnica diferente. Todos los vamos a guardar en una lista de objetos tipo clasificador de `sklearn`.\n",
    "\n",
    "Una ventaja de `sklearn` es que todos los objetos clasificador se pueden ajustar sus parámetros en la inicialización, y todos (sean del tipo que sean) utilizan varios métodos, siempre de la misma manera, en particular: `clf.fit` para el aprendizaje y `cls.predict`para el reconocimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificadores = [\n",
    "    KNeighborsClassifier(3),                  # 3 vecinos próximos\n",
    "    SVC(kernel=\"linear\", C=0.025),            # SVC lineal con C = 0.025\n",
    "    SVC(gamma=2, C=1),                        # SVC gaussiano con gamma = 2 y C = 1\n",
    "    DecisionTreeClassifier(max_depth=5),      # Árbol de decisión con máxima profundidad de 5\n",
    "    RandomForestClassifier(max_depth=5,       # Bósque aleatorios con 10 árboles con una característica\n",
    "                           n_estimators=10, \n",
    "                           max_features=1),\n",
    "    AdaBoostClassifier(),                     # ADA Boost (con árboles de profundidad 1)\n",
    "    GaussianNB(),                             # Naive bayes con distribución gaussiana\n",
    "    LogisticRegression(solver='lbfgs'),       # Logística \n",
    "    QuadraticDiscriminantAnalysis()           # Logística con términos cuadráticos sin regularización\n",
    "]\n",
    "\n",
    "# Solo para fines de graficación\n",
    "titulos = [\"3 vecinos próximos\", \n",
    "           \"SVM lineal\", \n",
    "           \"SVM gaussiano\", \n",
    "           \"Árbol de desición\",\n",
    "           \"Boseques aleatórios\", \n",
    "           \"AdaBoost\", \n",
    "           \"Naive Bayes\", \n",
    "           \"Logística\",\n",
    "           \"Discriminante cuadrático\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Generando la clasificación con cada método diferente\n",
    "\n",
    "Por cada método establecido, y por cada conjunto de datos, vamos a realizar la clasificación con los datos de aprendizaje, y luego vamos a realizar la predicción con un monton de puntos del espacio (en forma de rejilla) con tal de poner de manifiesto cual es el tipo de partición que induce cada uno de los algoritmos propuestos.\n",
    "\n",
    "Esto se realiza en forma genética, así que es exactamente igual para todos los mñetodos. Por esto se utilizan varios comandos provenientes de `matplotlib`para generar los datos para reconocer en forma de rejilla, y se realizan algunas operaciones no tan comunes para graficar, que se espera no haya problema en entenderlas, al ser solo un problema técnico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Vamos a escoger una escala de colores de alto contraste\n",
    "cm = plt.cm.RdBu\n",
    "cm_escala = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "for (cual, ds) in enumerate(datasets):\n",
    "    \n",
    "    print('\\n' * 3)\n",
    "    print(\"*\"*30 + \"\\n\")\n",
    "    print(\"Base de datos \" + str(cual + 1))\n",
    "    print(\"*\"*30 + \"\\n\")\n",
    "    figure = plt.figure(figsize=(30, 30))\n",
    "\n",
    "\n",
    "    # Escalar y selecciona valores de entrenamiento y prueba\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4)\n",
    "\n",
    "    # Meshgrid para pintar las regiones\n",
    "    xx, yy = np.meshgrid(np.arange(X[:, 0].min() - .5, X[:, 0].max() + .5, 0.02),\n",
    "                         np.arange(X[:, 1].min() - .5, X[:, 1].max() + .5, 0.02))\n",
    "\n",
    "    # Por cada clasificador\n",
    "    for (i, (titulo, clf)) in enumerate(zip(titulos, clasificadores)):\n",
    "        \n",
    "        # Escoge el subplot\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        \n",
    "        # El entrenamiento!!!!\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Encuentra el error de validación\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # Clasifica cada punto en el meshgrid\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        # Asigna un color a cada punto\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Grafica los datos de entrenamiento y prueba\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_escala, s=150)\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_escala, s=150, alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        ax.set_title(titulo, size=30)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=30, horizontalalignment='right')\n",
    "\n",
    "    figure.subplots_adjust(left=.02, right=.98)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 1.\n",
    "\n",
    "Para cada una de las técnicas, describe en que casos crees que la técnica sería de las mejores técnics a utilizar como método de clasificación (puedes consultar bibbliografía o solo apoyarte en los resultados, pero tiene que ser congruente).\n",
    "\n",
    "1. **3 vecinos próximos**: Agrega tu comentario aquí.\n",
    "\n",
    "2. **SVM lineal**: Agrega tu comentario aquí.\n",
    "\n",
    "3. **SVM gaussiano**: Agrega tu comentario aquí.\n",
    "\n",
    "4. **Árbol de desición**: Agrega tu comentario aquí.\n",
    "\n",
    "5. **Boseques aleatórios**: Agrega tu comentario aquí.\n",
    "\n",
    "6. **AdaBoost**: Agrega tu comentario aquí.\n",
    " \n",
    "7. **Naive Bayes**: Agrega tu comentario aquí. \n",
    "\n",
    "8. **Discriminante lineal**: Agrega tu comentario aquí.\n",
    "\n",
    "9. **Discriminante cuadrático**: Agrega tu comentario aquí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Curvas de aprendizaje\n",
    "\n",
    "En esta sección vamos a ver como se pueden aplicar tanto las curvas de aprendizaje (para ver si un método es suficiente (o no), así como las curvas de validación (o calibración) para ver si los parámetros que estámos usando provocan sobreaprendizaje o subaprendizaje (o están bien, por supuesto). \n",
    "\n",
    "Para esto vamos a utilizar una famosisima base de datos, la de los dígitos escritos a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "\n",
    "for index, (image, label) in enumerate(zip(digits.images[:16], digits.target[:16])):\n",
    "    plt.subplot(4, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Este es un %i' % label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Curvas de aprendizaje\n",
    "\n",
    "Para hacer las curvas de aprendizaje vamos a hacer una función envolvente (wrap function) de manera que sea más fácil aplicarla a diferentes ejemplos. Esta función envolvente es propuesta dentro de la documentación de `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curva_aprendizaje(estimator, title, X, y, ylim=None, cv=None,\n",
    "                           n_jobs=1, train_sizes=np.linspace(.1, 1.0, 10)):\n",
    "    \"\"\"\n",
    "    Genera una curva de aprendizaje\n",
    "\n",
    "    estimator : Objeto clasificador con métodos `fit` y `predict`\n",
    "\n",
    "    title : Titulo de la figura.\n",
    "\n",
    "    X : `ndarray` con shape (n_nuestras, n_atributos)\n",
    "\n",
    "    y : `ndarray` con shape (n_muestras) \n",
    "\n",
    "    ylim : tupla (ymin, ymax), opcional. Máximos y mínimos en la gráfica.\n",
    "\n",
    "    cv : int, cross-validation generator, opcional. Número de folders en K-fold-cross-validation\n",
    "\n",
    "    n_jobs : int, opcional. Número de tareas en paralelo.\n",
    "    \n",
    "    train_sizes : ndarray. Valores a los cuales se hace un punto para gener la curva de aprendizaje\n",
    "    \"\"\"\n",
    "\n",
    "    # EL marco de la gráfica\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(u\"Ejemplos de entrenamiento\")\n",
    "    plt.ylabel(u\"Error de predicción\")\n",
    "    \n",
    "    ####################################################################\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    ####################################################################\n",
    "    \n",
    "    train_mean = np.mean(1 - train_scores, axis=1)\n",
    "    train_std = np.std(1 - train_scores, axis=1)\n",
    "    test_mean = np.mean(1 - test_scores, axis=1)\n",
    "    test_std = np.std(1 - test_scores, axis=1)\n",
    "\n",
    "    plt.fill_between(train_sizes, train_mean - train_std,\n",
    "                     train_mean + train_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_mean - test_std,\n",
    "                     test_mean + test_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_mean, 'o-', color=\"r\",\n",
    "             label=u\"Entrenamiento\")\n",
    "    plt.plot(train_sizes, test_mean, 'o-', color=\"g\",\n",
    "             label=u\"Validación\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Analizando el clasificador naive bayes\n",
    "\n",
    "Ahora vamos a utilizar el clasificador *Naive Bayes* y vamos a ver que problemas podría presentar en la clasificación. En el caso del Naive Bayes, al ser un modelo generativo, el aprendizaje es muy rápido, por lo que vamos a aplicar el método unas 100 veces, pero sin validación cruzada, ya que en ese caso sería muy lento. De esta manera, vamos a tener una estimación correcta no solo de la curva de aprendizaje promedio, si no de su envolvente a una desviación estandar hacia arriba y hacia abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación cruzada con 100 folders (20 por ciento de datos de validación)\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "# Clasificador tipo Naive bayes gaussiano\n",
    "clf = GaussianNB()\n",
    "\n",
    "#Curva de aprendizaje\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "plot_curva_aprendizaje(clf, \"Curva de aprendizaje (Naive Bayes)\", \n",
    "                       X, y, ylim=(0, 0.3), cv=cv, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2.\n",
    "\n",
    "Responde a las siguiente preguntas:\n",
    "\n",
    "1. ¿Hay alto sezgo, alta varianza, o el resultado es correcto?\n",
    "2. ¿Hay sobre aprendizaje, sub aprendizaje o es correcto?\n",
    "3. ¿Se necesitarían más datos?\n",
    "4. Indica 3 posibles acciones a considerar en este caso (de ser necesario).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Analizando una máquina de vector de soporte con kernel gaussiano\n",
    "\n",
    "En este caso, vamos a analizar un clasificador cuyo aprendizaje es más complejo (y por lo tanto toma más tiempo). Por esta razón vamos a limitarnos a una validación cruzada de 10 folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación cruzada de 10 folders (20 por ciento de datos de validación)\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "\n",
    "# Clasificador SVM con kernel gaussiano y gamma=0.001\n",
    "clf = SVC(gamma=0.001)\n",
    "\n",
    "\n",
    "#Curva de aprendizaje\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "plot_curva_aprendizaje(clf, \"Curva de aprendizaje (SVM, kernel RBF, $\\gamma=0.001$)\", \n",
    "                       X, y, ylim=(0, 0.1), cv=cv, n_jobs=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 3.\n",
    "\n",
    "Responde a las siguiente preguntas:\n",
    "\n",
    "1. ¿Hay alto bias, alta varianza, o el resultado es correcto?\n",
    "2. ¿Hay sobre aprendizaje, sub aprendizaje o es correcto?\n",
    "3. ¿Se necesitarían más datos?\n",
    "4. Indica 3 posibles acciones a considerar en este caso (de ser necesario).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Curva de validación para el parámetro $\\gamma$\n",
    "\n",
    "Vamos ahora a graficar la curva de validación para diferentes parámetros de $\\gamma$ sobre el clasificador por máquinas de vactores de soporte con kernel gaussiano. Dado que los cambios que se pueden percibir son muy pequeños, a menos que el parámetro de varía en forma logarítmica (esto es, en relación a sus ordenes de magnitud), pues la curva de validación la vamos a realizar utilizando una escala logarítmica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los valores que le vamos a dar a \\gamma\n",
    "param_range = np.logspace(-6, -1, 5)\n",
    "\n",
    "# La curva de validación con 10 fold-cross-validation\n",
    "train_scores, test_scores = validation_curve(SVC(), X, y, \n",
    "                                             param_name=\"gamma\", \n",
    "                                             param_range=param_range,\n",
    "                                             cv=10, \n",
    "                                             scoring=\"accuracy\", \n",
    "                                             n_jobs=1)\n",
    "\n",
    "train_mean = np.mean(1 - train_scores, axis=1)\n",
    "train_std = np.std(1 - train_scores, axis=1)\n",
    "\n",
    "test_mean = np.mean(1 - test_scores, axis=1)\n",
    "test_std = np.std(1 - test_scores, axis=1)\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "\n",
    "# Plot de los resultados de entrenamiento\n",
    "plt.semilogx(param_range, train_mean, label=\"Entrenamiento\", color=\"r\")\n",
    "plt.fill_between(param_range, \n",
    "                 train_mean - train_std,\n",
    "                 train_mean + train_std, \n",
    "                 alpha=0.2, color=\"r\")\n",
    "\n",
    "# Plot de los resultados de validación\n",
    "plt.semilogx(param_range, test_mean, label=u\"Validación cruzada\", color=\"g\")\n",
    "plt.fill_between(param_range, \n",
    "                 test_mean - test_std,\n",
    "                 test_mean + test_std, \n",
    "                 alpha=0.2, color=\"g\")\n",
    "\n",
    "plt.title(u\"Curva de validación de SVM con kernel gaussiano al variar $\\gamma$\")\n",
    "plt.xlabel(u\"Parámetro $\\gamma$\")\n",
    "plt.ylabel(u\"Error de clasificación\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 4.\n",
    "\n",
    "Responde a las siguiente preguntas:\n",
    "\n",
    "1. ¿En que valor de $\\gamma$ hay claramente sobreaprendizaje?\n",
    "2. ¿En que valor de $\\gamma$ hay claramente subaprendizaje?\n",
    "3. ¿Cual sería a t consideración el mejor valor de $\\gamma$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Automatización de tareas\n",
    "\n",
    "Hacer las tareas repetitivas, tales como ajustar parámetros, o utilizar una serie de pasos en un proceso de reconocimiento de partones, son el tipo de problemas que son claramente automatizables. En esta sección vamos a ver como automatizar dos tareas: el uso de un método de preprocesamiento de señales conectado a un mñetodo de clasificación utilizando un `pipeline`; y el proceso de optimización de los valores de los parámetros utilizando curvas de validación (calibración). \n",
    "\n",
    "Recuerda que estos son solo dos ejemplos de formas de automatización y que existen otros más ya contemplados dentro de la librería `sklearn`.\n",
    "\n",
    "### 3.1. Automatización de procedimientos que se realizan en serie\n",
    "\n",
    "Vamos a asumir que queremos realizar el reconocimiento de digitos escritos a mano (el mísmo conjunto de datos original), pero ahora utilizando otro enfoque. Vamos a preprocesar los datos utilizando análisis en componentes principales (PCA), y luego aplicando un clasificador por regresión logística con regularización. \n",
    "\n",
    "Es importante de ver que en el aprendizaje hay que ajustar la matriz de transformación y la normalización de datos en el PCA, para luego utilizar esos resultados para el ajuste de los pesos del regresor logístico. De la misma manera, para reconocer nuevos datos, es necesario normalizarlos y rotarlos de acuerdo al algoritmo de PCA, para que su resultado sea utilizado dentro de la regresión logística. Así, las operacions (tanto de reconocimiento como aprendizaje) se hacen en serie, o en `pipeline` para utilizar un término muy común para quienes utilizan la linea de comandos en UNIX.\n",
    "\n",
    "Vamos entonces a definir un *pipeline* con estas dos unidades de procesamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El tratamiento de los datos por PCA \n",
    "# con la asignación por default de sus parámetros\n",
    "pca = PCA()\n",
    "\n",
    "# El clasificador, por regresión logística\n",
    "# con la asignación por default de sus parámetros\n",
    "logistic = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "\n",
    "# Siempre que se haga entrenamiento o predicción, hay que\n",
    "# aplicar pca primero y logistic después\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('acp', pca), \n",
    "        ('logistica', logistic)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Ahora en pipe tenemos un clasificador, de tal forma que \n",
    "# pipe.fit(X, y) ajusta ambos métodos, y\n",
    "# pipe.predict(X) realiza la prediccion (entre otros operadores genéricos de un clasificador)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Optimizador de parámetros por curvas de validación\n",
    "\n",
    "Como es posible observar, no es necesario visualizar las curvas de calibración, ya que el mejor valor para una variable es cuando el error de validación es el menor posible. Así que es claro que la tarea de encontra el mejor valor posible para uno o varios parámetros, es probar sobre un conjunto de valores, y seleccionar los valores de los parámetros que ofrezcan el menor error de validación posible.\n",
    "\n",
    "Al ser esta una tarea fácilmente automatizable, es de esperar que exista ya algo así dentro del modulo de `sklear`. Y efectivamente, existe, para un conjunto finito y predefinido de valores en los cuales buscar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se escogen dos parámetros a ajustas: \n",
    "#       a) El número de componentes principales del PCA\n",
    "#       b) El valor de C (regularización) para la regresión logística\n",
    "\n",
    "# EL número de componentes principales podrá ser 20, 40 o todos\n",
    "n_componentes = [20, 40, 64]\n",
    "\n",
    "# El parámetro C varia como 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000\n",
    "Cs = np.logspace(-4, 4, 8)\n",
    "\n",
    "# Genera un clasificador con optimizador de parámetros en el aprendizaje\n",
    "#        a) Utiliza el clasificador definido en pipe\n",
    "#        b) Los parámetros a ajustar se ponen en un diccionario {var1: valores_var1, var2:valores_var2}\n",
    "#        c) pca__n_components es equivalente a pipe.pca.n_components (para poderlo poner en strings)\n",
    "#        d) logistic__C es equivalente a la variable pipe.logistic.C\n",
    "# \n",
    "# Al ser el clasificador un pipeline, los parámetros se encuentran en esa forma de la estructura.\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    pipe,\n",
    "    dict(\n",
    "        acp__n_components= n_componentes,\n",
    "        logistica__C= Cs\n",
    "    ),\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "# Ahora clf es un objeto clasificador, que si se ejecuta clf.fit(X,y)\n",
    "# ajusta los objetos pca y logistic y ajusta los parámetros pca.n_components y logistic.C de\n",
    "# acuerdo al conjunto de posibles parámetros que le introducimos. El reconocimiento y el resto de\n",
    "# las funciones son similares a las que tenía pipe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Aplicando el aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, y)\n",
    "\n",
    "print(\"El mejor valor de regularización es: {}\".format(clf.best_estimator_.named_steps['logistica'].C))\n",
    "print(\"El número óptimo de componentes principales es: {}\".format(clf.best_estimator_.named_steps['acp'].n_components))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 5.\n",
    "\n",
    "Prueba de realizar la clasificación de los digitos utilizando un clasificador por máquina de vector de soporte con kernel lineal combinado con análisis en componentes principales.\n",
    "\n",
    "1.  Encuentra los mejores valores para al menos dos parámetros diferentes.\n",
    "\n",
    "2. Grafica la curva de aprendizaje y escribe las posibles ventajas y desventajas del método en relación a los métodos de Naive Bayes y de SVM con kernel gaussiano vistos anteriormente\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
